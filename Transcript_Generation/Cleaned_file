 In this video, I will give you a highlevel overview of all the different container services you can use on AWS. So if you want to run a containerized application on AWS, you have multiple options to choose from depending on your application requirements. So well go through all of these options one by one. We will see what ECS elastic container service is and what its used for. Then well compare it and talk about EKS which is Elastic Kubernetes Service, we will also see different ways of running containers with EC2 or AWS Fargate and finally we will see the ECR service which stands for Elastic Container Registry. Now think about a microservice application scenario. If youre developing microservices, you would need. containers for each and containers scale pretty quickly. Maybe you create replicas. You have different thirdparty services and applications for your microservice application. This could be messaging systems, authentication services, et cetera. So you end up with a bunch of containers that you need to deploy on some environment. In this case, were talking about AWS virtual service. So lets say we have created 10 containers for each our 10 microservices, plus we have five other containers that our microservices use, which run different applications. And lets say we deploy all of those on our EC2 instances, which have Docker installed on them. Now, once you have deployed them, how do you manage them? So you have an infrastructure of all these virtual servers that are running all your Docker containers. Oh no. how much resources you still have remaining on these machines. How do you know where to schedule the next container? How do you know by looking across your infrastructure whether some of your Docker containers are not running anymore? Whether servers ran out of resources and when you see that some containers have died, do you manually restart each container? If you have maybe five replicas of one application container. You dont need anymore. How do you get rid of all those containers? Do you stop them and remove them one by one? And these are all things that you need to manage when you have tens of containers, maybe hundreds of containers, that you need to manage on your infrastructure. So obviously you need some kind of automation, some kind of tool that can help you with all these issues. And all these things that I just mentioned are. features of a container orchestration tool. So you probably already know one of them, which is the most popular orchestration tool Kubernetes, but of course, there are multiple orchestration tools out there. Docker Swarm is one of them, which is for less complex, a bit smaller, containerized applications. You also have mesos, Apache mesos. You also have Hashikorb Nomad. And you also have. an AWS service called Amazon Elastic Container Service, ECS. So ECS is one of the container services that AWS offers and it is essentially a container orchestration service. So ECS being an orchestrator for containers will manage the whole life cycle of a container. When you start the container, even its so good. rescheduled somewhere, if you need to get restarted, load balanced, etc. So how does this service actually work? On AWS, if you wanted to create a cluster, a container cluster, basically, that is managed by AWS ECS service, you would create an ECS cluster. And that ECS cluster will basically contain all the services that are necessary. for managing the individual containers. So ECS cluster basically represents a control plane for all your virtual machines that are running containers. And that control plane and the services, the managing services, in that control plane that can manage this individual containers, and essentially managing the whole lifecycle of a container from being started scheduled to. being removed. When you create ECS cluster, as I said, you have the control plane, but the containers need to run somewhere, right? So containers need to run on actual machines, on virtual machines. So where do these virtual machines come from? These virtual machines will be the EC2 instances. We would create an EC2 instance that will basically host the containers. The EC2 will not be isolated. and managed by us completely, but EC2 instance will be connected to this ECS cluster that we created. And on those EC2 instances you will have the Docker runtime or container runtime generally so that containers can run, and also youre going to have ECS agents installed. And this way the control plane or ECS processes can communicate with each individual EC2 instance and manage them. So, in the end, it means that you have a control plane that helps you manage all your containers and automate some of these complex things that you dont want to do manually and repeatedly. So, you have delegated the management of your containers to an AWS service, so you dont have to worry about that. However, you still have to manage the actual virtual machines, the EC2 instances. So, in the end, you have to manage the actual virtual machines, the EC2 instances. Meaning, you have to create the EC2 instances, you have to join them to the ECS cluster. And when you schedule a new container, you have to make sure that you have enough EC2 instances and resources to schedule the next container. You also have to manage the server operating system, and you also have Docker runtime and the ECS agent, as I mentioned. So all these are basically part of a virtual machine that you have to still manage. On the upside, of course, you have full access to your infrastructure, which is an advantage if you need full configuration, access and power of the infrastructure thats running your containers. So now you have delegated the management of your containerized application or your containers basically to the AWS service, which of course makes your operations easier. However, you still have the. infrastructure to manage the virtual servers. Now what if you wanted to delegate management of the infrastructure also to AWS? So you want the container lifecycle to be managed by AWS and you want the hosting infrastructure to also be managed by AWS. Now there is an option for that and it is called AWS4G So fargate is basically an alternative to EC2 instances. So instead of creating a provisioning EC2 instances and connecting that to the ECS cluster, you dont need to provision any virtual machines. You use Fargate interface and Fargate will take care of spinning up the VM to run your container. So how does Fargate work? Fargate is a serverless way to launch containers. So you take. container that you want to deploy on AWS. And you tell AWS, heres my container, please run it. And you hand it over to Fargate. Now at this point, you dont have any virtual machine that will run your container. You havent provisioned anything or any server yet. You just have the control plane of ECS and you have the Fargate interface. So you give your container to Fargate and you say, please schedule. Fargate will then take your container, it will analyze by looking at your container how much resources your container needs to run. How much CPU, how much RAM, how much storage it needs to be deployed into a run. And then Fargate will itself automatically provision a server resources for that specific container. And then it will deploy and run that container on the provision. server resources. So this happens automatically. And every time you add or you hand over a new container to be deployed to Fargate, Fargate will do the same. You go and provision server resources to run that specific container. So advantages are obviously you dont need to worry about having enough EC2 instances and resources to schedule a new container because you dont have to provision anything beforehand. And because you dont have to provision the infrastructure beef. before you deploy containers, you always have only the amount of infrastructure resources needed to run your containers. And that means you pay only for the resources that your containers are actually consuming. And also, it really easily scales without fixed set of EC2 resources defined beforehand since every new container gets new resources. And pricing is based on how long the container. runs and how much CPU and memory was requested for that container. So for comparison, for EC2, you obviously pay for the whole server, even though you might not be running any containers on it or just a few maybe, and for Fargate, you only pay for the resources that container is consuming. So now you have your infrastructure managed by AWS using the Fargate service and containers that are running, that were scheduled through Fargate are now also managed by ECS. So we have multiple levels of your infrastructure and application on it being managed by AWS services. Now the only thing that you have to worry about and manage is the actual application itself. So you develop the application, you create containers and thats it. And then you just deploy the containers. AWS infrastructure, which obviously is a great thing. However, again, if you need more access to the underlying infrastructure, you need access to the actual infrastructure, running your containers, then you have the flexibility and access with EC2 instances. And of course, when you run your containerized application on AWS infrastructure, using the AWS services, you have advantage of using any. other AWS services from the AWS ecosystem. So both EC2 and Fargate and ECS, and all these services obviously fully integrate with the whole AWS ecosystem. So this could be cloud watch for monitoring elastic load balancer for load balancing, IAM for permissions and users, VPC for networking, and so on. Now this is how you can let AWS manage your containerized applications using ECS. Now what if you want to use Kubernetes? As you know Kubernetes is the most popular container orchestration tool currently. So a lot of projects and a lot of companies actually use Kubernetes. So can you still use AWS infrastructure if you want to use Kubernetes? And how can you use that? U.S. actually has another service which is for managing Kubernetes cluster on AWS infrastructure. So alternative to ECS, you have a service called EKS which stands for Elastic Kubernetes Service that lets you manage Kubernetes cluster. So the difference or advantage of using EKS is the first thing that I just mentioned which is if you are using Kubernetes or. and your project wants to deploy their Kubernetes cluster on AWS infrastructure. Obviously, you want to be able to keep your Kubernetes tool and not use a proprietary container orchestration of AWS. You have an option of doing that using EKS. So thats the first obvious reason. Another reason if you do not necessarily think about using Kubernetes or you dont already use Kubernetes. in your project, making decision between ECS and EKS is basically ECS is specific to AWS, right? So if you decide at some later point to migrate to another platform, you will not be able to move that cluster to another platform because it is really integrated and based on AWS. With EKS though, because its managing the Kubernetes cluster, you can easily migrate Kubernetes because its not specific to AWS, right? an independent tool which you can use anywhere. So you can migrate much easily migrate Kubernetes cluster on another platform or maybe even on premise, right? If you have your own infrastructure in your company, then you can use the same configuration, same tools across multiple platforms. So thats a major advantage of using EKS versus ECS. Now I have to mention here that even though Kubernetes is an independent tool if youre using it on AWS and you use a lot of additional tools and services from the AWS ecosystem in your Kubernetes cluster. Then of course, when you migrate your Kubernetes cluster, you will have to replace those services with some other tools because they will not be available on another platform, right? Because these services are again specific to AWS. So just know that its not 100 easily migratable. especially if youre using AWS specific services in your cluster. So thats maybe one thing to consider. Another also important reason for using EKS versus ECS is that if you use Kubernetes, which is again, much more popular orchestration tool than ECS, you also have access to all the Kubernetes tools and plugins and things are developing in the Kubernetes ecosystem, like Helm and some other tools that integrate well. with Kubernetes. Now on the side of ECS, a more suitable use case for ECS is if you have less complex containerized applications that maybe dont need this full fledged Kubernetes cluster to run in, in this case, you can actually deploy it on ECS cluster. And also, you dont pay for the ECS control plane compared to EKS cluster control plane. But generally, I think EKS. is much better choice for managing and orchestrating your cluster on AWS infrastructure. Now, how does EKS work? Its actually pretty similar to how ECS works. With EKS, you create a cluster, which represents the control plane. In Kubernetes world, these are gonna be the master nodes. So when you create an EKS service or EKS cluster, AWS will provision in the background. Kubernetes master notes that already have all the Kubernetes master services installed on them. So all of that is managed and provisioned for you. You dont have to worry about master notes for your Kubernetes cluster. Also because its managed by AWS, this master notes, it will automatically replicate the master notes across multiple availability zones. So if youre creating EKS in region, EU West 3 that has three availability zones, then you will get automatic replication of your master notes on all those A, Zs. And of course, then you have the storage, which is the LCD part of the master processes, which stores the whole configuration, the current state basically of Kubernetes cluster. And that storage needs to be replicated and needs to be backed up because you shouldnt or you cant lose the data otherwise. you lose all your cluster configuration. And again, because its a managed service, AWS will also take care of storing the data, replicating it and baking it up properly. So basically, master notes of Kubernetes is not your worry anymore. So with EKS, you have the master notes control plane configure. Now you need the worker notes, right? You need infrastructure that actually runs your containers. Again, same way as in the EC. you will create easy to instances, the socalled compute fleet of multiple virtual servers, and then connect them to the EKS. And I have the master nodes and worker node group connected, and that gives you a complete Kubernetes cluster. And once thats done, you can simply connect to the cluster using Cubsitial command and start deploying containers inside that cluster. In the ECS we saw that these EC2 instances, this compute fleet, each server had the ECS agent installed. This way the control plane could communicate with the individual nodes. In this case, were in the Kubernetes world, so worker nodes will have Kubernetes processes. So this way, control plane or Kubernetes master nodes can communicate with worker nodes just like they do on any platform. Its not specific to AWS in this case. So you have the worker nodes made out of EC2 instances that are connected to the EKS cluster. However, in this case, also, you need to manage the EC2 instances yourself. You have to manage the operating system and the processes running on them. In EKS cluster, however, you have a possibility to choose a semimanaged EC2 instances for your cluster. So basically, you can group your. worker nodes into node groups and that node group can actually handle some of the heavy lifting for you and basically make it easier for you to configure new worker nodes for your cluster. For example worker nodes or easytoinstances managed by node group will get all the processes necessary installed on them so you dont have to worry about installing container runtime, Kubernetes worker Rocker most et cetera, for them to make it into worker nodes. So that means you have an alternative between completely selfmanaged EC2 instances and semimanaged EC2 instances through node groups. And when working with EKS cluster, it is actually a good practice to use node groups because they make a lot of things simpler and you can also create multiple node groups to group your worker nodes in different logical groups. But other sees are troublesome. I said it is still semimanaged, you still have to take care of some other stuff. For example, auto scaling. You dont have the auto scaling configuration out of the box. You still need to configure things in Kubernetes and on the AWS side to make auto scaling possible. So you have to take care of creating new EC2 instances, removing them, etc. However, if thats also something you want to delegate to AWS, if. If you dont want to worry about that, you can also for EKS cluster use Fargate instead. And in that case, you would have fully managed worker nodes in addition to fully managed control plane. So these are the three steps of worker node infrastructure management. You have available in AWS. Or you can even use both EC2 and Fargate at the same time for the same. EKS cluster. So basically from the hosting perspective of where your containers are running, having EC2 and Fargate as alternatives, this part is pretty much the same whether you use ECS or EKS. And this basically gives you the combination of the services that you have as an option if you want to run a containerized application on AWS. using a container orchestration tool to manage them. Now we just saw two of the services on AWS that are specifically for containers, and there is one more container service on AWS, and that is Amazon ECR, which stands for Elastic Container Registry. So basically this is just a repository for container images. So alternative to Docker Hub or Nexus, Docker repository where you can store your Docker images, for example. Advantage of using Elastic Container Registry is of course because its part of the whole AWS ecosystem, it integrates well with other services. So for example, if you use EKS with EC2 instances, for example, then it will be easier to that and configure your cluster with ECR to fetch the instances but also to do some other stuff like automatically get notified when a new version of the image gets pushed to the registry and then automatically download that into your cluster. And also some other additional features and of course you have all those abilities because these are all AWS services so they are tightly integrated with each other. And ECR is pretty easy and straightforward to use. You basically create your private repositories for your different application images or Docker images. And you can start pushing different versions or different tags of that image to those registries. And then of course, use that endpoint to download the images from the cluster. So to summarize. on AWS you have three container services, first for storing container images in private container repository, and the other two for orchestrating or managing your complex containerized application on AWS infrastructure. And in this part were going to look at ECR in EK services and use them in our CICD pipeline to build and push in. to ECR and deploy them to Elastic Coventry Service. 